{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9165f8ac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-14T16:10:07.949959Z",
     "iopub.status.busy": "2025-12-14T16:10:07.949566Z",
     "iopub.status.idle": "2025-12-14T16:10:10.128826Z",
     "shell.execute_reply": "2025-12-14T16:10:10.127994Z"
    },
    "papermill": {
     "duration": 2.187089,
     "end_time": "2025-12-14T16:10:10.130496",
     "exception": false,
     "start_time": "2025-12-14T16:10:07.943407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/audio-samples/Audio_Samples'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02e4710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:10:10.139145Z",
     "iopub.status.busy": "2025-12-14T16:10:10.138581Z",
     "iopub.status.idle": "2025-12-14T16:10:10.144253Z",
     "shell.execute_reply": "2025-12-14T16:10:10.143437Z"
    },
    "papermill": {
     "duration": 0.011339,
     "end_time": "2025-12-14T16:10:10.145513",
     "exception": false,
     "start_time": "2025-12-14T16:10:10.134174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# This is for Ignoreing unwanted WARNINGS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b31cf8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:10:10.154030Z",
     "iopub.status.busy": "2025-12-14T16:10:10.153440Z",
     "iopub.status.idle": "2025-12-14T16:11:43.823920Z",
     "shell.execute_reply": "2025-12-14T16:11:43.822757Z"
    },
    "papermill": {
     "duration": 93.67689,
     "end_time": "2025-12-14T16:11:43.825868",
     "exception": false,
     "start_time": "2025-12-14T16:10:10.148978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8612bd90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:43.878819Z",
     "iopub.status.busy": "2025-12-14T16:11:43.878480Z",
     "iopub.status.idle": "2025-12-14T16:11:53.170135Z",
     "shell.execute_reply": "2025-12-14T16:11:53.168953Z"
    },
    "papermill": {
     "duration": 9.320068,
     "end_time": "2025-12-14T16:11:53.171827",
     "exception": false,
     "start_time": "2025-12-14T16:11:43.851759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 258MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"base\", device=\"cpu\")\n",
    "print(\"DONE!\")\n",
    "\n",
    "# result = model.transcribe(audio_path)\n",
    "# text = result[\"text\"]\n",
    "# print(\"text: \",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad1295",
   "metadata": {
    "papermill": {
     "duration": 0.026002,
     "end_time": "2025-12-14T16:11:53.223885",
     "exception": false,
     "start_time": "2025-12-14T16:11:53.197883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load Whisper Model (Speech → Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb186006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:53.278459Z",
     "iopub.status.busy": "2025-12-14T16:11:53.277506Z",
     "iopub.status.idle": "2025-12-14T16:11:53.285078Z",
     "shell.execute_reply": "2025-12-14T16:11:53.284122Z"
    },
    "papermill": {
     "duration": 0.036739,
     "end_time": "2025-12-14T16:11:53.286591",
     "exception": false,
     "start_time": "2025-12-14T16:11:53.249852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Convert text to Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove fillers common in speech\n",
    "    fillers = [\n",
    "        r\"\\buh\\b\", r\"\\bum\\b\", r\"\\bhmm\\b\", r\"\\bah\\b\",\n",
    "        r\"\\ber\\b\", r\"\\beh\\b\"\n",
    "    ]\n",
    "    for f in fillers:\n",
    "        text = re.sub(f, \"\", text)\n",
    "\n",
    "    # 3. Remove repeated words from text\n",
    "    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n",
    "\n",
    "    # 4. Remove unwanted characters from text\n",
    "    text = re.sub(r\"[^a-z0-9\\s\\.\\,\\?\\!]\", \"\", text)\n",
    "\n",
    "    # 5. Fix extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# text = \"I I think this is is a very very good example. It show grammar mistake.\"\n",
    "# print(clean_text(text))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff16266",
   "metadata": {
    "papermill": {
     "duration": 0.026724,
     "end_time": "2025-12-14T16:11:53.341591",
     "exception": false,
     "start_time": "2025-12-14T16:11:53.314867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Text Cleaning (Speech-Specific)**\n",
    "Remove fillers, repetitions, and noise without correcting grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e64bbb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:53.396729Z",
     "iopub.status.busy": "2025-12-14T16:11:53.395819Z",
     "iopub.status.idle": "2025-12-14T16:11:56.421991Z",
     "shell.execute_reply": "2025-12-14T16:11:56.420917Z"
    },
    "papermill": {
     "duration": 3.055489,
     "end_time": "2025-12-14T16:11:56.423944",
     "exception": false,
     "start_time": "2025-12-14T16:11:53.368455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# import re \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db0f165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:56.478459Z",
     "iopub.status.busy": "2025-12-14T16:11:56.477879Z",
     "iopub.status.idle": "2025-12-14T16:11:56.488613Z",
     "shell.execute_reply": "2025-12-14T16:11:56.487570Z"
    },
    "papermill": {
     "duration": 0.039744,
     "end_time": "2025-12-14T16:11:56.490046",
     "exception": false,
     "start_time": "2025-12-14T16:11:56.450302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "def extract_grammar_features(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return {\n",
    "            \"error_ratio\": 1.0,\n",
    "            \"avg_sentence_length\": 0.0,\n",
    "            \"pos_consistency\": 0.0,\n",
    "            \"repetition_ratio\": 1.0\n",
    "        }\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    if len(words) == 0:\n",
    "        return {\n",
    "            \"error_ratio\": 1.0,\n",
    "            \"avg_sentence_length\": 0.0,\n",
    "            \"pos_consistency\": 0.0,\n",
    "            \"repetition_ratio\": 1.0\n",
    "        }\n",
    "\n",
    "    # Sentence length\n",
    "    avg_sentence_length = len(words) / max(len(sentences), 1)\n",
    "\n",
    "    # Repetition\n",
    "    from collections import Counter\n",
    "    word_counts = Counter(words)\n",
    "    repetition_ratio = sum(v for v in word_counts.values() if v > 1) / len(words)\n",
    "\n",
    "    # POS tagging (stable)\n",
    "    pos_tags = nltk.pos_tag(words, lang='eng')\n",
    "    pos_counts = Counter(tag for _, tag in pos_tags)\n",
    "    pos_consistency = max(pos_counts.values()) / len(pos_tags)\n",
    "\n",
    "    # Error proxy\n",
    "    grammar_errors = 0\n",
    "    for i in range(len(pos_tags) - 1):\n",
    "        t1 = pos_tags[i][1]\n",
    "        t2 = pos_tags[i + 1][1]\n",
    "\n",
    "        if t1 == t2 and t1 in [\"NN\", \"VB\", \"JJ\"]:\n",
    "            grammar_errors += 1\n",
    "        if t1 == \"DT\" and t2.startswith(\"VB\"):\n",
    "            grammar_errors += 1\n",
    "\n",
    "    error_ratio = grammar_errors / len(words)\n",
    "\n",
    "    return {\n",
    "        \"error_ratio\": round(error_ratio, 4),\n",
    "        \"avg_sentence_length\": round(avg_sentence_length, 2),\n",
    "        \"pos_consistency\": round(pos_consistency, 4),\n",
    "        \"repetition_ratio\": round(repetition_ratio, 4)\n",
    "    }\n",
    "# text = \"I I think this is is a very very good example. It show grammar mistake.\"\n",
    "# print(extract_grammar_features(text))\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b8fe9",
   "metadata": {
    "papermill": {
     "duration": 0.026017,
     "end_time": "2025-12-14T16:11:56.541709",
     "exception": false,
     "start_time": "2025-12-14T16:11:56.515692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Grammar Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c221e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:56.594708Z",
     "iopub.status.busy": "2025-12-14T16:11:56.594353Z",
     "iopub.status.idle": "2025-12-14T16:11:56.602012Z",
     "shell.execute_reply": "2025-12-14T16:11:56.601009Z"
    },
    "papermill": {
     "duration": 0.036253,
     "end_time": "2025-12-14T16:11:56.603396",
     "exception": false,
     "start_time": "2025-12-14T16:11:56.567143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "def grammar_score(features):\n",
    "    error_ratio = features[\"error_ratio\"]\n",
    "    repetition_ratio = features[\"repetition_ratio\"]\n",
    "    avg_sentence_length = features[\"avg_sentence_length\"]\n",
    "    pos_consistency = features[\"pos_consistency\"]\n",
    "\n",
    "\n",
    "    # Lower error \n",
    "    error_score = max(0, 1 - error_ratio * 2)\n",
    "\n",
    "    # Lower repetition\n",
    "    repetition_score = max(0, 1 - repetition_ratio * 2)\n",
    "\n",
    "    # Sentence length sweet spot (8–20)\n",
    "    if avg_sentence_length < 8:\n",
    "        length_score = avg_sentence_length / 8\n",
    "    elif avg_sentence_length > 20:\n",
    "        length_score = max(0, 1 - (avg_sentence_length - 20) / 20)\n",
    "    else:\n",
    "        length_score = 1.0\n",
    "\n",
    "    # POS consistency sweet range\n",
    "    if 0.3 <= pos_consistency <= 0.55:\n",
    "        pos_score = 1.0\n",
    "    else:\n",
    "        pos_score = max(0, 1 - abs(pos_consistency - 0.425) * 2)\n",
    "\n",
    "    # Weighted Sum for Final Grammar score\n",
    "    final_score = (\n",
    "        0.4 * error_score +\n",
    "        0.25 * repetition_score +\n",
    "        0.2 * length_score +\n",
    "        0.15 * pos_score\n",
    "    )\n",
    "\n",
    "    # Scale to 0–10\n",
    "    return round(final_score * 10, 2)\n",
    "\n",
    "\n",
    "# print(grammar_score(features))\n",
    "    \n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e6dfa",
   "metadata": {
    "papermill": {
     "duration": 0.02693,
     "end_time": "2025-12-14T16:11:56.656994",
     "exception": false,
     "start_time": "2025-12-14T16:11:56.630064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Rule-Based Grammar Scoring (0–10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c77109b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:56.711576Z",
     "iopub.status.busy": "2025-12-14T16:11:56.711220Z",
     "iopub.status.idle": "2025-12-14T16:11:56.720331Z",
     "shell.execute_reply": "2025-12-14T16:11:56.719232Z"
    },
    "papermill": {
     "duration": 0.038469,
     "end_time": "2025-12-14T16:11:56.721897",
     "exception": false,
     "start_time": "2025-12-14T16:11:56.683428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "#Base DIR of sample files\n",
    "AUDIO_DIR = '/kaggle/input/grammar-voice-samples/Audio_Samples'\n",
    "\n",
    "#Extracting Sample file path one by one and storeing\n",
    "audio_files = [\n",
    "    os.path.join(AUDIO_DIR, f)\n",
    "    for f in os.listdir(AUDIO_DIR)\n",
    "    if f.endswith(\".mp3\")\n",
    "]\n",
    "# print(audio_files)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a2ae84d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:11:56.778159Z",
     "iopub.status.busy": "2025-12-14T16:11:56.777764Z",
     "iopub.status.idle": "2025-12-14T16:12:12.341917Z",
     "shell.execute_reply": "2025-12-14T16:12:12.340925Z"
    },
    "papermill": {
     "duration": 15.594142,
     "end_time": "2025-12-14T16:12:12.343633",
     "exception": false,
     "start_time": "2025-12-14T16:11:56.749491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>transcription</th>\n",
       "      <th>error_ratio</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>pos_consistency</th>\n",
       "      <th>repetition_ratio</th>\n",
       "      <th>grammar_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample2.mp3</td>\n",
       "      <td>she likes football, play 2.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample3.mp3</td>\n",
       "      <td>the dog is barking loudly.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample6.mp3</td>\n",
       "      <td>we have working being on this project.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample1.mp3</td>\n",
       "      <td>is dog the barking loudly.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample4.mp3</td>\n",
       "      <td>they were going to their park yesterday.</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample5.mp3</td>\n",
       "      <td>grandparents will visit my eye tomorrow.</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    audio_file                             transcription  error_ratio  \\\n",
       "0  sample2.mp3               she likes football, play 2.       0.0000   \n",
       "1  sample3.mp3                the dog is barking loudly.       0.0000   \n",
       "2  sample6.mp3    we have working being on this project.       0.0000   \n",
       "3  sample1.mp3                is dog the barking loudly.       0.0000   \n",
       "4  sample4.mp3  they were going to their park yesterday.       0.1250   \n",
       "5  sample5.mp3  grandparents will visit my eye tomorrow.       0.1429   \n",
       "\n",
       "   avg_sentence_length  pos_consistency  repetition_ratio  grammar_score  \n",
       "0                  7.0           0.1429               0.0           8.90  \n",
       "1                  6.0           0.1667               0.0           8.73  \n",
       "2                  8.0           0.2500               0.0           9.48  \n",
       "3                  6.0           0.1667               0.0           8.73  \n",
       "4                  8.0           0.2500               0.0           8.47  \n",
       "5                  7.0           0.2857               0.0           8.19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for audio_path in audio_files:\n",
    "    # 1. Convert Text fromthe .mp3 voice samples by the WHISHPER\n",
    "    \n",
    "    #HOPE WHISHPER MODEL LOADED SUCCESSFULLY!\n",
    "    result = model.transcribe(audio_path)\n",
    "    raw_text = result[\"text\"]\n",
    "\n",
    "    # 2. Text Cleaning\n",
    "    clean_text_data = clean_text(raw_text)\n",
    "\n",
    "    # 3. Extract grammar features\n",
    "    features = extract_grammar_features(clean_text_data)\n",
    "\n",
    "    # 4. Getting Final Grammar score\n",
    "    score = grammar_score(features)\n",
    "\n",
    "    results.append({\n",
    "        \"audio_file\": os.path.basename(audio_path),\n",
    "        \"transcription\": clean_text_data,\n",
    "        \"error_ratio\": features[\"error_ratio\"],\n",
    "        \"avg_sentence_length\": features[\"avg_sentence_length\"],\n",
    "        \"pos_consistency\": features[\"pos_consistency\"],\n",
    "        \"repetition_ratio\": features[\"repetition_ratio\"],\n",
    "        \"grammar_score\": score\n",
    "    })\n",
    "\n",
    "#Final Output\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8cf769",
   "metadata": {
    "papermill": {
     "duration": 0.026973,
     "end_time": "2025-12-14T16:12:12.397414",
     "exception": false,
     "start_time": "2025-12-14T16:12:12.370441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Process All Audio Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "813c4e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T16:12:12.454492Z",
     "iopub.status.busy": "2025-12-14T16:12:12.454172Z",
     "iopub.status.idle": "2025-12-14T16:12:12.467248Z",
     "shell.execute_reply": "2025-12-14T16:12:12.466234Z"
    },
    "papermill": {
     "duration": 0.043349,
     "end_time": "2025-12-14T16:12:12.468719",
     "exception": false,
     "start_time": "2025-12-14T16:12:12.425370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved at: /kaggle/working/output/grammar_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = \"/kaggle/working/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "output_path = os.path.join(output_dir, \"grammar_scores.csv\")\n",
    "df_results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Output saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ce36e",
   "metadata": {
    "papermill": {
     "duration": 0.027369,
     "end_time": "2025-12-14T16:12:12.522367",
     "exception": false,
     "start_time": "2025-12-14T16:12:12.494998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Save Output to CSV**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9021908,
     "sourceId": 14154938,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 132.600943,
   "end_time": "2025-12-14T16:12:15.056011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T16:10:02.455068",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
